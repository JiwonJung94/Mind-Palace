# 001. MLOps 환경 구축하기

_"이제 진짜 MLOps의 세계로 들어가볼 시간이다!"_

---

## 🎯 이번 챕터에서 배울 것들

- Conda를 이용한 Python 환경 관리
- DVC(Data Version Control) 설정
- JupyterLab 확장 설치 및 설정
- Git과 DVC 연동
- 첫 번째 ML 프로젝트 구조 만들기

---

## 1. Conda 환경 설정하기

### 왜 Conda를 사용할까?

MLOps에서는 **재현 가능한 환경**이 핵심입니다. 팀원이 다른 환경에서도 동일한 결과를 얻을 수 있어야 하거든요.

```bash
# Miniconda 설치 (이미 설치되어 있다면 스킵)
wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh
bash Miniconda3-latest-Linux-x86_64.sh

# Conda 초기화
conda init bash
source ~/.bashrc
```

### MLOps 전용 환경 생성

```bash
# MLOps 환경 생성 (Python 3.9 사용)
conda create -n mlops python=3.9 -y
conda activate mlops

# 필수 패키지 설치
conda install -c conda-forge jupyterlab pandas scikit-learn matplotlib seaborn -y
conda install -c conda-forge dvc -y
```

### 환경 파일 생성

```bash
# 현재 환경의 패키지 목록 저장
conda env export > environment.yml

# requirements.txt도 생성 (호환성을 위해)
pip freeze > requirements.txt
```

---

## 2. DVC(Data Version Control) 설정

### DVC란?

DVC는 **데이터와 모델의 Git**이라고 생각하면 됩니다. 큰 파일들을 Git 대신 별도 저장소에 저장하고, Git에는 메타데이터만 저장해요.

### DVC 초기화

```bash
# Git 저장소가 있는 디렉토리에서
cd /path/to/your/mlops-project

# DVC 초기화
dvc init

# .dvc 파일들을 Git에 추가
git add .dvc .gitignore
git commit -m "Initialize DVC"
```

### 원격 저장소 설정

```bash
# 로컬 디렉토리를 원격 저장소로 설정 (예시)
dvc remote add -d storage /path/to/remote/storage

# 또는 클라우드 저장소 사용
# dvc remote add -d storage s3://my-bucket/dvc-storage
# dvc remote add -d storage gs://my-bucket/dvc-storage
```

---

## 3. JupyterLab 확장 설치

### 필수 확장들

```bash
# JupyterLab 확장 설치
jupyter labextension install @jupyterlab/git
jupyter labextension install @jupyterlab/toc
jupyter labextension install @jupyterlab/lsp
jupyter labextension install @jupyterlab/debugger

# JupyterLab 서버 확장
jupyter serverextension enable --py jupyterlab_git
```

### JupyterLab 설정

```python
# ~/.jupyter/jupyter_lab_config.py
c.ServerApp.allow_origin = '*'  # CORS 설정
c.ServerApp.open_browser = False
c.ServerApp.port = 8888
```

---

## 4. 프로젝트 구조 만들기

### 표준 MLOps 프로젝트 구조

```
mlops-project/
├── data/
│   ├── raw/           # 원본 데이터
│   ├── processed/     # 전처리된 데이터
│   └── external/      # 외부 데이터
├── notebooks/         # Jupyter 노트북
├── src/              # 소스 코드
│   ├── data/         # 데이터 처리
│   ├── features/     # 특성 엔지니어링
│   ├── models/       # 모델 정의
│   └── visualization/ # 시각화
├── models/           # 훈련된 모델
├── reports/          # 분석 보고서
├── tests/           # 테스트 코드
├── config/          # 설정 파일
├── .dvc/            # DVC 메타데이터
├── .gitignore
├── environment.yml   # Conda 환경
├── requirements.txt  # pip 패키지
└── README.md
```

### 프로젝트 초기화 스크립트

```python
# setup_project.py
import os

def create_mlops_structure():
    directories = [
        'data/raw', 'data/processed', 'data/external',
        'notebooks', 'src/data', 'src/features', 'src/models', 'src/visualization',
        'models', 'reports', 'tests', 'config'
    ]
    
    for directory in directories:
        os.makedirs(directory, exist_ok=True)
        print(f"Created: {directory}")
    
    # .gitignore 파일 생성
    gitignore_content = """
# Data files
*.csv
*.json
*.parquet
*.pkl
*.joblib

# Model files
*.pkl
*.joblib
*.h5
*.pb

# Jupyter Notebook checkpoints
.ipynb_checkpoints/

# Python cache
__pycache__/
*.pyc

# Environment
.env
.venv/

# IDE
.vscode/
.idea/

# OS
.DS_Store
Thumbs.db
"""
    
    with open('.gitignore', 'w') as f:
        f.write(gitignore_content)
    
    print("Created: .gitignore")

if __name__ == "__main__":
    create_mlops_structure()
```

---

## 5. 첫 번째 데이터 추가하기

### 샘플 데이터 다운로드

```python
# notebooks/01_data_exploration.ipynb
import pandas as pd
import requests
from sklearn.datasets import load_iris

# Iris 데이터셋 로드
iris = load_iris()
df = pd.DataFrame(iris.data, columns=iris.feature_names)
df['target'] = iris.target

# 데이터 저장
df.to_csv('../data/raw/iris.csv', index=False)
print("Iris 데이터셋이 data/raw/iris.csv에 저장되었습니다.")
```

### DVC로 데이터 추적

```bash
# 데이터를 DVC로 추적
cd data/raw
dvc add iris.csv

# .dvc 파일을 Git에 추가
git add iris.csv.dvc .gitignore
git commit -m "Add iris dataset"

# 원격 저장소에 데이터 업로드 (선택사항)
dvc push
```

---

## 6. 환경 검증하기

### 환경 테스트 스크립트

```python
# tests/test_environment.py
import sys
import subprocess

def test_environment():
    """MLOps 환경이 올바르게 설정되었는지 테스트"""
    
    # Python 버전 확인
    assert sys.version_info >= (3, 8), "Python 3.8 이상이 필요합니다"
    
    # 필수 패키지 확인
    required_packages = [
        'pandas', 'numpy', 'scikit-learn', 'matplotlib', 
        'seaborn', 'jupyter', 'dvc'
    ]
    
    for package in required_packages:
        try:
            __import__(package)
            print(f"✅ {package} 설치됨")
        except ImportError:
            print(f"❌ {package} 설치되지 않음")
            return False
    
    # DVC 상태 확인
    try:
        result = subprocess.run(['dvc', 'status'], capture_output=True, text=True)
        print("✅ DVC 정상 작동")
    except FileNotFoundError:
        print("❌ DVC가 설치되지 않음")
        return False
    
    print("\n🎉 모든 테스트 통과! MLOps 환경이 준비되었습니다.")
    return True

if __name__ == "__main__":
    test_environment()
```

---

## 🎯 다음 챕터 예고

다음 챕터에서는:
- **데이터 전처리와 특성 엔지니어링**
- **모델 훈련과 평가**
- **모델 버전 관리**
- **실험 추적 (MLflow 사용)**

환경 구축이 완료되었으니, 이제 진짜 ML 파이프라인을 만들어볼 시간입니다!

---

## 📚 참고 자료

- [Conda 공식 문서](https://docs.conda.io/)
- [DVC 공식 문서](https://dvc.org/)
- [JupyterLab 확장](https://jupyterlab.readthedocs.io/)
- [MLOps Best Practices](https://ml-ops.org/)

---

_"환경 구축은 지루할 수 있지만, 튼튼한 기초가 있어야 멋진 건물을 지을 수 있어요!"_
