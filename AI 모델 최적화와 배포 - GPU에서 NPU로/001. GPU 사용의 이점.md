GPU와 CPU는 서로 다른 목적을 위해 설계되었습니다. 이로 인해 성능과 활용도에서 큰 차이가 나타납니다.

CPU는 복잡한 작업을 순차적으로 빠르게 처리하는 데 최적화되어 있습니다. 소수의 고성능 코어를 가지고 있으며, 각 코어는 높은 클럭 속도로 작동합니다. CPU는 데이터 캐싱과 흐름 제어에 많은 트랜지스터를 할당하여 운영 체제, 제어 로직, 일반 애플리케이션과 같은 순차적인 작업에서 뛰어난 성능을 발휘합니다.

GPU는 대규모 병렬 계산을 수행하는 데 최적화되어 있습니다. 단일 코어의 클럭 주파수가 포화점에 도달함에 따라, 패러다임은 다중 코어 및 다수 코어 프로세서로 전환되었습니다. GPU는 수천 개의 작은 코어를 통해 수많은 스레드를 동시에 실행하며, 데이터 처리에 더 많은 트랜지스터를 할당하여 병렬 처리 성능을 극대화합니다. 이는 그래픽 렌더링, 딥러닝, 과학적 계산 등 고도로 병렬화된 작업에서 GPU가 CPU보다 훨씬 높은 성능을 발휘할 수 있는 이유입니다.

### CPU에서의 병렬성

명령어가 완료되기 위해 필요한 다섯 가지 필수 단계는 다음과 같습니다:
- **Instruction fetch (IF)**: 명령어를 메모리에서 가져옵니다.
- **Instruction decode (ID)**: 명령어를 디코딩하여 어떤 작업을 수행해야 하는지 파악합니다.
- **Instruction execute (Ex)**: 명령어를 실행합니다. 예를 들어, 산술 연산이나 논리 연산을 수행합니다.
- **Memory access (Mem)**: 메모리에 접근하거나 메모리에서 데이터를 읽거나 씁니다.
- **Register write-back (WB)**: 실행 결과를 레지스터에 씁니다.

이것은 기본적인 5단계 RISC 아키텍처입니다. 기본적으로, 비파이프라인(non-pipelined) CPU에서는 한 번에 하나의 명령어만 처리할 수 있습니다. 즉, 하나의 명령어가 다섯 단계를 모두 완료해야만 다음 명령어를 처리할 수 있습니다. 이렇게 하면 CPU의 일부 자원이 유휴 상태로 남게 되어 비효율적입니다.

#### 파이프라이닝 (Pipeline)

파이프라인은 CPU의 효율성을 극대화하기 위해 명령어 처리 단계를 병렬로 수행하는 기술입니다. 즉, 한 클럭 사이클 동안 서로 다른 명령어의 각기 다른 단계가 동시에 실행됩니다. 다섯 개의 명령어(I1, I2, I3, I4, I5)가 있다고 가정하면, 파이프라인에서 각 명령어는 다음과 같이 처리됩니다:

| 클럭 사이클 | 단계 1 (IF) | 단계 2 (ID) | 단계 3 (EX) | 단계 4 (MEM) | 단계 5 (WB) |
| ------ | --------- | --------- | --------- | ---------- | --------- |
| 1      | I1        |           |           |            |           |
| 2      | I2        | I1        |           |            |           |
| 3      | I3        | I2        | I1        |            |           |
| 4      | I4        | I3        | I2        | I1         |           |
| 5      | I5        | I4        | I3        | I2         | I1        |
| 6      |           | I5        | I4        | I3         | I2        |
| 7      |           |           | I5        | I4         | I3        |
| 8      |           |           |           | I5         | I4        |
| 9      |           |           |           |            | I5        |

위 표에서 볼 수 있듯이, 파이프라인이 가동되면 첫 번째 명령어(I1)가 완료되기까지 다섯 클럭 사이클이 필요하지만, 이후에는 매 클럭 사이클마다 하나의 명령어가 완료됩니다. 이제 우리는 하나의 클럭 사이클에서 많은 명령을 처리할 수 있습니다. 이는 처리량(Throughput)을 크게 증가시키는 효과를 가져옵니다.

파이프라인 구조는 효율적이지만, 명령어 간의 의존성 때문에 문제가 발생할 수 있습니다. 이를 **Hazard**라고 부르며, 주요 위험은 다음 세 가지입니다:

##### 1) 데이터 위험(Data Hazard):

- 데이터 위험은 명령어 간의 데이터 의존성 때문에 발생합니다.
- 예를 들어:
    - I1: R5에 1 더하기 (`ADD R5, R5, 1`)
    - I2: R5를 R6에 복사 (`MOV R6, R5`)
    - 여기서 I1이 R5를 업데이트하기 전에 I2가 R5의 값을 읽게 되면, I2는 업데이트되지 않은 값을 사용하게 됩니다.

##### 2) 제어 위험(Control Hazard):

- 분기 명령어(예: 조건문, 점프)로 인해 발생합니다.
- 다음에 실행할 명령어를 예측해야 하는 경우, 예측이 틀리면 파이프라인을 비우고 다시 시작해야 합니다.

##### 3) 구조적 위험(Structural Hazard):

- 동일한 하드웨어 자원을 두 개 이상의 명령어가 동시에 사용하려고 할 때 발생합니다.
- 예를 들어, 메모리 접근 단계에서 두 명령어가 동시에 메모리에 접근하려고 하면 충돌이 발생할 수 있습니다.


#### 슈퍼스칼라 (Superscalar)

슈퍼스칼라 아키텍처는 CPU 내부에 **여러 실행 유닛**(Execution Units)을 배치하여, 한 클럭 사이클 동안 여러 명령어를 동시에 처리할 수 있도록 설계된 구조입니다. 

파이프라인은 명령어를 여러 단계로 나누어 병렬로 처리하여 CPU 자원을 효율적으로 사용하는 기술이지만, 다음과 같은 문제점이 있습니다:

##### 1) 병렬성의 한계

- 파이프라인에서는 한 번에 하나의 명령어만 각 단계에서 처리됩니다.
- 즉, 한 클럭 사이클 동안 하나의 명령어만 디스패치되고 실행됩니다.
- 결과적으로, 파이프라인의 최대 처리량은 "한 클럭 사이클당 하나의 명령어"로 제한됩니다.

##### 2) 의존성 문제

- 명령어 간 데이터 의존성(Data Hazard)이나 제어 의존성(Control Hazard)이 발생하면, 파이프라인이 멈추거나 명령어를 재실행해야 합니다.
- 예를 들어, 이전 명령어의 결과가 다음 명령어의 입력으로 필요할 때, 파이프라인은 대기 상태(Stall)에 들어갑니다.

##### 3) 리소스 활용의 비효율성

- 파이프라인은 각 단계에서 특정 하드웨어 자원만 사용합니다.
- 한 번에 하나의 명령어만 처리되므로, CPU 내부의 많은 자원이 유휴 상태로 남을 수 있습니다.

슈퍼스칼라 아키텍처는 위와 같은 파이프라이닝의 문제를 다음과 같은 방식으로 해결합니다:

##### 1) 다중 실행 유닛을 통한 병렬 명령어 실행

- 슈퍼스칼라 프로세서는 여러 실행 유닛(ALU, FPU 등)을 포함하고 있어, 한 클럭 사이클 동안 여러 명령어를 동시에 실행할 수 있습니다.
- 예를 들어, 두 개의 ALU와 하나의 FPU가 있는 경우, 한 클럭 사이클 동안 산술 연산 두 개와 부동소수점 연산 하나를 동시에 실행할 수 있습니다.

###### 예시:

- 명령어 1: 산술 연산 (ADD)
- 명령어 2: 산술 연산 (SUB)
- 명령어 3: 부동소수점 연산 (MUL)

이 세 명령어는 서로 독립적이라면, 한 클럭 사이클 동안 동시에 실행될 수 있습니다.

##### 2) 명령어 디코딩 및 디스패치의 병렬화

- 슈퍼스칼라 아키텍처는 명령어를 디코딩한 후, 동시에 여러 실행 유닛으로 디스패치할 수 있습니다.
- 파이프라인에서는 한 번에 하나의 명령어만 디스패치하지만, 슈퍼스칼라에서는 여러 명령어를 동시에 디스패치합니다.

###### 예시:

- 두 개의 ALU와 하나의 FPU를 가진 CPU는 한 클럭 사이클 동안 최대 3개의 명령어를 디스패치할 수 있습니다.

##### 3) 명령어 추적 및 재정렬(Out-of-Order Execution)

- 슈퍼스칼라 프로세서는 명령어의 의존성을 분석하고, 실행 순서를 재정렬하여 병렬성을 극대화합니다.
- 예를 들어, 데이터 의존성이 없는 명령어는 순서에 상관없이 먼저 실행될 수 있습니다.

###### 예시:

- 명령어 1: `ADD R1, R2, R3` (R1 = R2 + R3)
- 명령어 2: `MUL R4, R5, R6` (R4 = R5 * R6)
- 명령어 3: `SUB R1, R4, R7` (R1 = R4 - R7)

여기서 명령어 2는 명령어 1, 3과 의존성이 없으므로 먼저 실행될 수 있습니다.

##### 슈퍼스칼라 아키텍처의 한계

1. **복잡한 설계**:
    - 명령어 디코딩, 디스패치, 추적, 재정렬 등의 과정이 복잡하여 설계 비용이 증가.

2. **명령어 의존성 문제**:
    - 데이터 의존성이나 자원 충돌이 여전히 발생할 수 있음.

3. **실행 유닛의 비효율적 사용**:
    - 실행 유닛이 많아도 병렬로 실행할 수 있는 명령어가 부족하면 유닛이 유휴 상태로 남을 수 있음.
















CPU에서 병렬성을 달성하는 여러 가지 방법이 있습니다. 먼저, 파이프라인이라고도 알려진 ILP(Instruction Level Parallelism)에 대해 논의하겠습니다.


### CUDA

**CUDA**(Compute Unified Device Architecture)는 NVIDIA가 만든 **병렬 컴퓨팅 플랫폼 및 프로그래밍 모델**이며, C 프로그래밍의 확장입니다. 쉽게 말해, **GPU를 활용해 복잡한 계산을 빠르게 처리할 수 있도록 도와주는 도구**입니다. 이 플랫폼은 일반 목적의 컴퓨팅을 위한 GPU를 노출합니다. CUDA는 GPU를 프로그래밍하고 관리하기 위한 C/C++ 언어 확장 및 API를 제공합니다.

CUDA 프로그래밍에서는 CPU와 GPU가 모두 계산에 사용됩니다. 일반적으로 CPU와 GPU 시스템을 각각 호스트와 장치로 지칭합니다. CPU와 GPU는 각자의 메모리 공간이 있는 분리된 플랫폼입니다. 일반적으로 CPU에서 직렬 작업을 실행하고 병렬 계산을 GPU에 오프로드합니다.

