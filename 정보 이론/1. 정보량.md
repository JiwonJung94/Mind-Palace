정보는 현대 사회에서 필수적인 자원으로, 우리는 매일 정보를 생성하고 소비합니다. 정보를 측정하는 것은 물리적 세계에서 질량, 길이, 속도 등을 측정하는 것과 비슷하게 수행될 수 있습니다. 이러한 맥락에서 **정보량**이라는 개념이 도입되었습니다. 정보량은 특정 정보를 결정하는 데 필요한 최소한의 질문(또는 이진 결정)의 수를 통해 정의됩니다.

정보량의 이론적 기초는 R.V.L. Hartley에 의해 제시되었습니다. Hartley는 정보를 수량화하기 위해 다음과 같은 공식을 사용했습니다:

$$
H = n \cdot \log(s) = \log(s^n)
$$

여기서:
- $n$은 특정 사건이나 선택지를 결정하기 위해 고려해야 할 가능한 결과의 수입니다.
- $s$는 각 결과가 발생할 수 있는 서로 다른 선택지의 수입니다.

이 공식은 주어진 선택지에서 특정 사건을 결정하는 데 필요한 정보량을 나타냅니다. 예를 들어, 알파벳 26자 중 하나를 특정하기 위해 필요한 질문의 수는 $\log_2(26)$입니다. 이는 약 4.7개의 이진 질문을 필요로 한다는 것을 의미합니다. 즉, 26개의 서로 다른 알파벳 중 하나를 정확히 식별하기 위해, 평균적으로 약 4.7번의 예/아니오 질문이 필요합니다.

이러한 개념은 정보 이론의 핵심으로, 정보량은 불확실성을 줄이기 위한 측정 도구로 사용됩니다. 정보량은 사건의 발생 확률과 밀접하게 관련되어 있으며, 확률이 낮을수록 더 많은 정보량이 필요합니다. 이는 직관적으로 이해할 수 있는데, 드문 사건일수록 그 사건에 대한 정보는 더 많은 가치를 지니고 있기 때문입니다. 따라서 정보량은 사건의 예측 가능성과 관련된 불확실성을 정량화하는 데 중요한 역할을 합니다.
